{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings\n",
    "from collections import deque\n",
    "\n",
    "warnings.filterwarnings('ignore', '.*Explicit initial center position passed: performing only one init in KMeans instead of n_init.*', )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whatever dataset you want and do the preproc ;)\n",
    "# However: for this to work, we need to have only two features (we want to visualize the clustering)\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_iris()\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset.feature_names)\n",
    "# target = pd.DataFrame(dataset['target'])\n",
    "display(df.head())\n",
    "\n",
    "# select the two features\n",
    "df = df[['sepal length (cm)', 'sepal width (cm)']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to normalize, comment this out:\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings \n",
    "eps = 0.3\n",
    "min_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_algo(df, eps, min_samples):\n",
    "    \"\"\"\n",
    "    df: input dataset. It must contains only two features\n",
    "    eps: \n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other. This is not a maximum bound\n",
    "        on the distances of points within a cluster. This is the most\n",
    "        important DBSCAN parameter to choose appropriately for your data set\n",
    "        and distance function.\n",
    "    min_samples: \n",
    "        The number of samples (or total weight) in a neighborhood for a point\n",
    "        to be considered as a core point. This includes the point itself.\n",
    "    \"\"\"\n",
    "    X = np.array(df.copy())\n",
    "    nn = NearestNeighbors(\n",
    "            radius=eps,\n",
    "            metric=\"euclidean\",\n",
    "        )\n",
    "    nn.fit(X)\n",
    "\n",
    "    # for each datapoint find all its neighbors\n",
    "    neighborhoods = nn.radius_neighbors(X, return_distance=False)\n",
    "    n_neighbors = np.array([len(neighbors) for neighbors in neighborhoods])\n",
    "\n",
    "    labels = np.full(X.shape[0], -1, dtype=np.intp)\n",
    "    core_samples = np.asarray(n_neighbors >= min_samples, dtype=np.uint8)\n",
    "    yield core_samples, labels, [], 0\n",
    "    yield core_samples, labels, [], 0\n",
    "    \n",
    "    k = -1\n",
    "    for i, core in enumerate(core_samples):\n",
    "        if core and labels[i] == -1:\n",
    "            k += 1\n",
    "            q = deque()\n",
    "            q.append(i)\n",
    "            while len(q) != 0:\n",
    "                curr = q.popleft()\n",
    "                labels[curr] = k\n",
    "                for j in neighborhoods[curr]:\n",
    "                    if core_samples[j]:\n",
    "                        if labels[j] == -1:\n",
    "                            labels[j] = k\n",
    "                            q.append(j)\n",
    "                            yield core_samples, labels, curr, 1\n",
    "                    elif labels[j] == -1:\n",
    "                        labels[j] = k\n",
    "                        yield core_samples, labels, curr, 1\n",
    "                        \n",
    "    yield core_samples, labels, [], 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: you can also not hard set init. In this first step (this is just an example)\n",
    "generator = start_algo(df, eps, min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects = ax.scatter(df[df.columns[0]], df[df.columns[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(A, rects):\n",
    "    # core_samples, labels, [], 2\n",
    "    ax.clear()\n",
    "    if A[3] == 0:\n",
    "        ax.scatter(df[df.columns[0]], df[df.columns[1]])\n",
    "    if A[3] == 1:\n",
    "        ax.scatter(df[df.columns[0]], df[df.columns[1]], c=A[1])\n",
    "        ax.scatter(df[df.columns[0]][A[2]], df[df.columns[1]][A[2]], c='red')\n",
    "        text = ax.text(0.01, 0.95, \"\", transform=ax.transAxes)\n",
    "        text.set_text(\"Red point: current core point for density connect\")\n",
    "    if A[3] == 2:\n",
    "        ax.scatter(df[df.columns[0]], df[df.columns[1]], c=A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = FuncAnimation(fig, func=animate, fargs=(rects,), frames=generator, interval=20,\n",
    "                     repeat=False, save_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will output the animation\n",
    "a = HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if visualizer did right:\n",
    "model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "l = model.fit_predict(df)\n",
    "plt.scatter(df[df.columns[0]], df[df.columns[1]], c=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"examples/dbscan.html\", \"w\") as f:\n",
    "#     print(anim.to_jshtml(), file=f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1be463f8d0b1cf702f36528853e07f729e457ba79e304c70b6a4c3fa692a8b40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
