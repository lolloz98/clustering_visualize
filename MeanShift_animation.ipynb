{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.cluster import get_bin_seeds\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whatever dataset you want and do the preproc ;)\n",
    "# However: for this to work, we need to have only two features (we want to visualize the clustering)\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_wine()\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset.feature_names)\n",
    "# target = pd.DataFrame(dataset['target'])\n",
    "display(df.head())\n",
    "\n",
    "# select the two features\n",
    "df = df[['alcohol', 'color_intensity']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to normalize, comment this out:\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_algo(X, bandwidth=None, seeds=None, bin_seeding=True, max_iter=1000, cluster_all=True):\n",
    "    \"\"\"\n",
    "    Implemantation taken and modified from: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html\n",
    "    \"\"\"\n",
    "    m = MeanShift(bandwidth=bandwidth, bin_seeding=bin_seeding, seeds=seeds,max_iter=max_iter, cluster_all=cluster_all)\n",
    "    # X = np.array(X)\n",
    "    X = m._validate_data(X)\n",
    "    bandwidth = m.bandwidth\n",
    "    if bandwidth is None:\n",
    "        bandwidth = estimate_bandwidth(X, n_jobs=None)\n",
    "    seeds = m.seeds    \n",
    "    if seeds is None:\n",
    "        if m.bin_seeding:\n",
    "            seeds = get_bin_seeds(X, bandwidth, m.min_bin_freq)\n",
    "        else:\n",
    "            seeds = X\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    center_intensity_dict = {}\n",
    "\n",
    "    nbrs = NearestNeighbors(radius=bandwidth).fit(X)\n",
    "    all_res = []\n",
    "    seeds_copy = [[i[0], i[1]] for i in seeds]\n",
    "    for i in range(len(seeds)):\n",
    "        # For each seed, climb gradient until convergence or max_iter\n",
    "        bandwidth = nbrs.get_params()[\"radius\"]\n",
    "        stop_thresh = 1e-3 * bandwidth  # when mean has converged\n",
    "        completed_iterations = 0\n",
    "        while True:\n",
    "            # Find mean of points within bandwidth\n",
    "            i_nbrs = nbrs.radius_neighbors([seeds_copy[i]], bandwidth, return_distance=False)[0]\n",
    "            points_within = X[i_nbrs]\n",
    "            if len(points_within) == 0:\n",
    "                break  # Depending on seeding strategy this condition may occur\n",
    "            my_old_mean = seeds_copy[i]  # save the old mean\n",
    "\n",
    "            seeds_copy[i] = np.mean(points_within, axis=0)\n",
    "            yield seeds_copy, X, []\n",
    "\n",
    "            # If converged or at max_iter, adds the cluster\n",
    "            if (\n",
    "                np.linalg.norm(seeds_copy[i] - my_old_mean) < stop_thresh\n",
    "                or completed_iterations == max_iter\n",
    "            ):\n",
    "                break\n",
    "            completed_iterations += 1\n",
    "        all_res.append((tuple(seeds_copy[i]), len(points_within), completed_iterations))\n",
    "        # print('about to yield')\n",
    "        yield seeds_copy, X, []\n",
    "\n",
    "    yield seeds_copy, X, []\n",
    "    \n",
    "    # Post process\n",
    "    # copy results in a dictionary\n",
    "    for i in range(len(seeds)):\n",
    "        if all_res[i][1]:  # i.e. len(points_within) > 0\n",
    "            center_intensity_dict[all_res[i][0]] = all_res[i][1]\n",
    "    m.n_iter_ = max([x[2] for x in all_res])\n",
    "\n",
    "    if not center_intensity_dict:\n",
    "        # nothing near seeds\n",
    "        raise ValueError(\n",
    "            \"No point was within bandwidth=%f of any seed. Try a different seeding\"\n",
    "            \" strategy                              or increase the bandwidth.\"\n",
    "            % bandwidth\n",
    "        )\n",
    "\n",
    "    sorted_by_intensity = sorted(\n",
    "        center_intensity_dict.items(),\n",
    "        key=lambda tup: (tup[1], tup[0]),\n",
    "        reverse=True,\n",
    "        )\n",
    "    sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])\n",
    "    unique = np.ones(len(sorted_centers), dtype=bool)\n",
    "    nbrs = NearestNeighbors(radius=bandwidth).fit(sorted_centers)\n",
    "    for i, center in enumerate(sorted_centers):\n",
    "        if unique[i]:\n",
    "            neighbor_idxs = nbrs.radius_neighbors([center], return_distance=False)[0]\n",
    "            for n in neighbor_idxs:\n",
    "                prv = unique[n]\n",
    "                unique[n] = 0\n",
    "                unique[i] = 1  # leave the current point as unique\n",
    "                if prv:\n",
    "                    yield sorted_centers[unique], X, []\n",
    "\n",
    "    cluster_centers = sorted_centers[unique]\n",
    "    yield cluster_centers, X, []\n",
    "    \n",
    "    # ASSIGN LABELS: a point belongs to the cluster that it is closest to\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(cluster_centers)\n",
    "    labels = np.zeros(n_samples, dtype=int)\n",
    "    distances, idxs = nbrs.kneighbors(X)\n",
    "    if m.cluster_all:\n",
    "        labels = idxs.flatten()\n",
    "    else:\n",
    "        labels.fill(-1)\n",
    "        bool_selector = distances.flatten() <= bandwidth\n",
    "        labels[bool_selector] = idxs.flatten()[bool_selector]\n",
    "    # print(labels)\n",
    "    # print('about to return')\n",
    "    m.cluster_centers_ = cluster_centers\n",
    "    m.labels_ = labels\n",
    "    yield cluster_centers, X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = start_algo(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects = ax.scatter(df[df.columns[0]], df[df.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ax.text(0.01, 0.95, \"\", transform=ax.transAxes)\n",
    "iteration = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(A):\n",
    "    ax.clear()\n",
    "    # print(A[2])\n",
    "    if len(A[2]) == 0:\n",
    "        ax.scatter(df[df.columns[0]], df[df.columns[1]])\n",
    "    else:\n",
    "        ax.scatter(df[df.columns[0]], df[df.columns[1]], c=[A[2]])\n",
    "    ax.scatter([i[0] for i in A[0]], [i[1] for i in A[0]], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = FuncAnimation(fig, func=animate, frames=generator, interval=100,\n",
    "                     repeat=False, save_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will output the animation\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if visualizer did right:\n",
    "from sklearn.cluster import MeanShift\n",
    "m = MeanShift(bin_seeding=True)\n",
    "l = m.fit_predict(df)\n",
    "plt.scatter(df[df.columns[0]], df[df.columns[1]], c=l)\n",
    "plt.scatter([i[0] for i in m.cluster_centers_], [i[1] for i in m.cluster_centers_], c='red')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1be463f8d0b1cf702f36528853e07f729e457ba79e304c70b6a4c3fa692a8b40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
